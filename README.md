# Module 2: Web-Crawler for Web-1.0/Web-2.0
---
### Стек
- GO: возможность параллельной работы программы
- chromedp: возможность загрузки динамического контента (JavaScript)
- Redis: ускорение обращения к ресурсу засчет кэширования DNS сервера для домена
- PostgreSQL: хранилище собранных данных

---

На данном этапе, запустить работу этой программы вы сможете установив PostreSQL 17 и Redis. Таблица в базе данных инициализируется автоматически.
Также вам потребуется файл **settings.json** с настройками среды работы программы. Прописать настройки согласно вашей среде разработки, например:
```json
{
    "mode" : "spider",
    "main_domain" : "toscrape.com",
    "toDownload": "https://toscrape.com",
    "dns_servers":[
        "1.1.1.1",
        "8.8.8.8",
        "9.9.9.9",
        "208.67.222.222"
    ],
    "dbconfig":{
        "host" :    "host",
        "port":     8888,
        "user":     "user",
        "password": "password",
        "dbname":   "dbname",
        "ssl_mode":  "disable"
    },
    "redisconfig":{
        "host" : "host:9999",
        "expiration" : 1
    }
}
```
**Чтобы вывести статистику по ключевому домену используйте "mode" : "stat"**


Особенностью этой работы является возможность запуска работы **веб-краулера** на параллельно работающих горутинах.
Контейнеризация в докере является незаконченной и желательной перспективой этого проекта, но в силу особенности стека и его эффективности, на реализацию потребовалось бы больше времени.